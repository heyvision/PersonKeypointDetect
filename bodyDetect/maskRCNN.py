import sys
sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')

import torch
import torchvision
import numpy as np
import cv2
import pyrealsense2 as rs
import time
import colorsys
import random

COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',
    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',
    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

#Generated by random_colors(10)
MASK_COLORS = [
    (0.2, 1.0, 0.0), (0.8, 1.0, 0.0), (0.0, 1.0, 0.4), (0.0, 1.0, 1.0), 
    (0.0, 0.4, 1.0), (1.0, 0.0, 0.6), (0.2, 0.0, 1.0), (0.8, 0.0, 1.0), 
    (1.0, 0.0, 0.0), (1.0, 0.6, 0.0)]

def random_colors(N, bright=True):
  """
  Generate random colors.
  To get visually distinct colors, generate them in HSV space then
  convert to RGB.
  """
  brightness = 1.0 if bright else 0.7
  hsv = [(i / N, 1, brightness) for i in range(N)]
  colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))
  random.shuffle(colors)
  return colors

def predict(src, model):
  img_cv = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)
  #tensor_cv = np.transpose(img_cv, (2, 0, 1))
  tensor_cv = torchvision.transforms.ToTensor()(img_cv)
  tensor_cv = tensor_cv.cuda()

  # print (tensor_cv.size())
  # print(next(model.parameters()).is_cuda)
  x = [tensor_cv]

  predictions = model(x)

  boxes = predictions[0]['boxes'].cpu().detach().numpy()
  labels = predictions[0]['labels'].cpu().detach().numpy()
  scores = predictions[0]['scores'].cpu().detach().numpy()
  masks = predictions[0]['masks'].cpu().detach().numpy()
  boxes_num = boxes.shape[0]
  # mask_colors = random_colors(boxes_num)
  count = 0
  for i in range(boxes_num):
    if(scores[i] > 0.7): #first person
      cv2.rectangle(src, (boxes[i][0], boxes[i][1]), 
          (boxes[i][2], boxes[i][3]), (255,0,0), 2)

      label_name = COCO_INSTANCE_CATEGORY_NAMES[labels[i]]
      cv2.putText(src, label_name + str(round(scores[i], 3)), 
          (boxes[i][0], boxes[i][1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

      mask = masks[i][0]
      color = MASK_COLORS[count % len(MASK_COLORS)]
      alpha = 0.5
      for c in range(3):
        src[:, :, c] = np.where(mask >= 0.5, 
          src[:, :, c] * (1 - alpha) + alpha * color[c] * 255, src[:, :, c])
      count += 1
  return src


def main():

  pipeline = rs.pipeline()
  config = rs.config()
  config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)
  config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)

  # Start streaming
  profile = pipeline.start(config)
  depth_sensor = profile.get_device().first_depth_sensor()
  # depth_sensor.set_option(rs.option.visual_preset, rs.Preset.HighAccuracy)
  depth_scale = depth_sensor.get_depth_scale()
  clipping_distance_in_meters = 3 # 3 meter
  clipping_distance = clipping_distance_in_meters / depth_scale

  align_to = rs.stream.color
  align = rs.align(align_to)

  model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)
  model = model.cuda()
  model.eval()

  frame_count = 0
  try:
    while True:
      time_start = time.time()
      frames = pipeline.wait_for_frames()
      aligned_frames = align.process(frames)
      aligned_depth_frame = aligned_frames.get_depth_frame()
      color_frame = aligned_frames.get_color_frame()
      if not aligned_depth_frame or not color_frame:
        continue
      color_image = np.asanyarray(color_frame.get_data())
      pred_img = predict(color_image, model)
      cv2.imshow("prediction", pred_img)
      cv2.waitKey(1)
      frame_count += 1
      print('time cost:',round(time.time()-time_start, 4), 's')

  finally:
    pipeline.stop()

def one_image():
  src = cv2.imread('/home/hit/Pictures/test2_Color.png')
  # src = cv2.resize(src, (320, 180))
  model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)
  model = model.cuda()
  model.eval()

  pred_img = predict(src, model)
  cv2.imshow("prediction", pred_img)
  cv2.waitKey(0)

if __name__ == "__main__":
  if torch.cuda.is_available():
    print("Device",torch.cuda.get_device_name(0),"is available")
  else:
    print("Cuda is unavailable")

  main()
  #one_image()